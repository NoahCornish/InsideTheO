name: Daily Roster Scraper

on:
  schedule:
    - cron: '0 5 * * *'  # Run every day at 4:10 AM
  workflow_dispatch: # Allows manual triggering of the workflow

jobs:
  scrape_rosters:
    runs-on: ubuntu-latest
    steps:
      # Step 1: Check out the repository
      - name: Checkout code
        uses: actions/checkout@v3

      # Step 2: Set up Python
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: 3.9

      # Step 3: Install dependencies
      - name: Install dependencies
        run: |
          pip install requests pandas

      # Step 4: Run the Python script
      - name: Run roster scraper
        run: python get_rosters.py

      # Step 5: Move the CSV to "OHL Rosters" folder
      - name: Move CSV to folder
        run: |
          mkdir -p "OHL Rosters"  # Create the folder if it doesn't exist
          mv rosters_updated.csv "OHL Rosters/"

      # Step 6: Check for changes
      - name: Check for changes
        id: check_changes
        run: |
          if [ -n "$(git status --porcelain)" ]; then
            echo "changes=true" >> $GITHUB_ENV
          else
            echo "changes=false" >> $GITHUB_ENV
          fi

      # Step 7: Commit and push CSV file if there are changes
      - name: Commit and push CSV
        if: env.changes == 'true'
        run: |
          git config --global user.name "github-actions[bot]"
          git config --global user.email "github-actions[bot]@users.noreply.github.com"
          git add "OHL Rosters/rosters_updated.csv"
          git commit -m "Update OHL Rosters/rosters_updated.csv [skip ci]"
          git push

      # Step 8: Log message if there are no changes
      - name: No changes to commit
        if: env.changes == 'false'
        run: echo "NO CHANGES TO OHL ROSTERS"
